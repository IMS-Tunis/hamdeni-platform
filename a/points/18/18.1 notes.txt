## 18.1 Point 1: Show understanding of how graphs can be used to aid Artificial Intelligence (AI)

Graphs are a key data structure in AI, representing relationships between data points. They are used in various AI applications for solving problems involving paths, networks, and relational data.

Key Concepts in Graphs:
- Node (Vertex): Represents an entity, such as a location, object, or point in a network.
- Edge: Represents the connection or relationship between two nodes.
- Weights: Numerical values representing the cost, distance, or time associated with the connection.
- Path: A sequence of edges connecting two nodes.
- Artificial neural networks can be drawn as graphs, where each neuron is a node and each connection is an edge. A value (weight) can be attached to each connection to show how strongly one neuron influences another.

Applications of Graphs in AI:
1. Pathfinding and Navigation: Finding the shortest or optimal route in GPS systems.
2. Network Routing: Optimizing data transfer in communication networks.
3. Knowledge Representation: Representing relationships between concepts, such as in semantic networks.

Graph Search Algorithms:
1. Dijkstra’s Algorithm:
- Used to find the shortest path between two nodes in a weighted graph.
- Dijkstra’s algorithm finds the best route from one node to all of the remaining nodes.
- Process:
  - Assign initial distances to all nodes (infinity for all except the start node, which is 0).
  - Update the distances of neighboring nodes iteratively.
  - Select the node with the smallest distance and mark it as finalized.
  - Repeat until the shortest path to the destination is determined.

2. A Algorithm*:
- A search algorithm that uses both actual costs (g(n)) and estimated costs to the goal (h(n)) to find the shortest path.
- Formula:
  - f(n) = g(n) + h(n), where:
    - g(n): Cost from the start node to the current node.
    - h(n): Heuristic estimate of the cost from the current node to the goal.
- A* algorithm is based on Dijkstra, but adds an extra heuristic (h) value, an intelligent guess on how far we have to go to reach the destination most efficiently.
- Key Features:
  - More efficient in finding paths in large graphs.

## 18.1 Point 2: Show understanding of how artificial neural networks have helped with machine learning

Artificial Neural Networks are computational models inspired by the structure and functioning of the human brain. They process data through interconnected layers of nodes (neurons) to identify patterns and make predictions.

Structure of ANNs:
1. Input Layer:
- Receives raw data, such as images, text, or numerical values.
2. Hidden Layers:
- Hidden layers process the input by combining the inputs using numerical connection strengths called weights. A bias is an extra adjustable value added to help the neuron produce the right output, and an activation function is a rule that converts the combined value into the neuron’s output signal.
- Extract features and patterns.
3. Output Layer:
- Produces the final result, such as a classification (e.g., spam or not spam) or prediction (e.g., next word in a sentence).

Key Features of ANNs:
- Weights: Determine the importance of input data during processing.
- Each neuron multiplies each input by its weight, adds these weighted values together, and then applies an activation function (a rule that converts the total into an output value).
- If the input is not a numerical value it must be converted to one so that the weighted values can be summed.
- Training: ANNs learn by adjusting weights based on error feedback during training.

Advantages of ANNs:
- Capable of handling large datasets and identifying patterns.
- Versatile in applications like image recognition, voice recognition, and natural language processing.

## 18.1 Point 3: Show understanding of Deep Learning, Machine Learning and Reinforcement Learning and the reasons for using these methods

Machine Learning (ML):
Machine learning enables systems to learn from data and improve performance without explicit programming. It is divided into three categories:
1. Supervised Learning:
- Uses labelled data (data with known outputs) for training.
- Supervised learning can be used in two common ways: classification, where the output is a category (for example, spam or not spam), and regression, where the output is a number (for example, a predicted house price).
- Example tasks: Predicting housing prices, spam detection.
2. Unsupervised Learning:
- Finds hidden patterns in unlabelled data.
- Unlabelled data is data without predefined categories and the system learns without explicit labels.
- Groups data into clusters based on similarity, and finds associations between data items.
- Example tasks: Customer segmentation.
3. Reinforcement Learning:
- An agent learns to make decisions by interacting with its environment.
- Rewards and penalties guide the learning process.
- Example tasks: Robotics, game AI.

Deep Learning (DL):
Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers to process data and learn hierarchical features.
- In a deep learning network, each connection between two neurons has a weight, which is a number that controls how strongly the signal from one neuron affects the next neuron.
Key Concepts:
- Processes data through multiple layers of neurons, each layer extracting more abstract features.
- Suitable for tasks like image recognition, speech synthesis, and autonomous driving.

## 18.1 Point 4: Show understanding of back propagation of errors and regression methods in machine learning

Backpropagation:
Backpropagation is an optimization technique used in training artificial neural networks. It minimizes errors by adjusting the weights of connections based on feedback from the output layer.
It is applied first to the nodes in the output layer and then works backward through the nodes in hidden layers.
Key Steps:
1. Forward Pass: Input data is processed, and predictions are made.
2. Error Calculation: The difference between predicted and actual outputs is calculated.
3. Backward Pass: The network sends the error information backward from the output layer to earlier layers and slightly adjusts the weights to reduce the error. This adjustment method is called gradient descent, which means changing the weights step by step in the direction that makes the error smaller.
4. Repeat: This process continues until the error is minimized.

Regression in Machine Learning:
Regression is a statistical technique used to model relationships between variables and make continuous predictions.
It helps us understand how an output value (dependent variable, such as house price) changes when one or more input values (independent variables, such as area or number of rooms) change. This makes regression useful for prediction tasks such as weather forecasting.
Key Features:
- Linear Regression: Models a straight-line relationship between variables.
- Polynomial Regression: Models a curved (non-linear) relationship between inputs and outputs by using a polynomial equation, such as one that includes squared or cubed terms (for example, x²).
Applications:
- Predicting sales trends.
- Forecasting weather patterns.
- Estimating housing prices.
